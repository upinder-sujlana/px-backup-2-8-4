Ques. How to get initial password of the install ?
Ans.
~/Desktop/Temporary
❯ kubectl --kubeconfig=k2 -n argocd get secret argocd-initial-admin-secret -o yaml | grep password
  password: d1pEQm0xYm1PVVcyRW5IaQ==

~/Desktop/Temporary
❯ echo "d1pEQm0xYm1PVVcyRW5IaQ==" | base64 -d
wZDBm1bmOUW2EnHi%
~/Desktop/Temporary
❯
//--------------------------------------------------------------------------------------------------------------
Ques. What are the CRD installed when Argocd integrates with a k8s cluster ?
Ans
kmaster2@kmaster2:~$ kubectl api-resources  | grep -iE "kind|argo"
NAME                              SHORTNAMES                                                APIVERSION                                  NAMESPACED   KIND
applications                           app,apps                                                  argoproj.io/v1alpha1                                      true         Application
applicationsets                   appset,appsets                                            argoproj.io/v1alpha1                                      true         ApplicationSet
appprojects                       appproj,appprojs                                          argoproj.io/v1alpha1                                       true         AppProject
kmaster2@kmaster2:~$
//--------------------------------------------------------------------------------------------------------------
Ques. Sample app ?
Ans.
https://github.com/yogeshraheja/Argo-CD-for-the-Absolute-Beginners.git
//--------------------------------------------------------------------------------------------------------------
Ques. What is a project in argocd ?
Ans.
The core idea of an Argo CD Project is segmentation and control. It's about organizing your applications and defining what they can and cannot do, and where they can and cannot go.
    Argo CD Project = "The Rules for a Set of Applications"
    It answers:
        "WHERE can these apps go?" (Clusters & Namespaces)
        "WHERE can these apps come from?" (Git Repositories)
        "WHO can touch these apps?" (Argo CD Users/Roles)

By using Projects, you enforce consistency, security, and proper organizational boundaries within your Argo CD deployments.

//--------------------------------------------------------------------------------------------------------------
Ques. Where is the app installed ?
Ans.
kmaster2@kmaster2:~$ kubectl get app -A
NAMESPACE   NAME               SYNC STATUS   HEALTH STATUS
argocd      grade-submission   Synced        Healthy
kmaster2@kmaster2:~$
//--------------------------------------------------------------------------------------------------------------
Ques. How to change 180 secreconciliation time ?
Ans.
# Application reconciliation timeout is the amount of time spent before Argo tries to discover if a new manifests version got
  # published to the repository. Reconciliation by timeout is disabled if timeout is set to 0. Two minutes by default with additional jitter.
  # > Note: The argocd-repo-server deployment and the argocd-application-controller statefulset (or deployment, if
  # configured) must be manually restarted after changing the setting.
  Go here: https://argo-cd.readthedocs.io/en/stable/operator-manual/declarative-setup/
  than click argocd-cm.yaml
  https://argo-cd.readthedocs.io/en/stable/operator-manual/argocd-cm-yaml/


kmaster2@kmaster2:~$ kubectl -n argocd describe app grade-submission | grep Recon
  Reconciled At:          2025-06-15T23:04:37Z
kmaster2@kmaster2:~$


kmaster2@kmaster2:~$ kubectl -n argocd get cm argocd-cm -o yaml | grep -i timeout.recon
  timeout.reconciliation: 180s
kmaster2@kmaster2:~$

After changing the time:
kubectl rollout restart deployment argocd-repo-server -n argocd
kubectl rollout restart sts argocd-application-controller -n argocd
//--------------------------------------------------------------------------------------------------------------
Ques. How to add a kubernetes cluster to argocd using argocd cli?
Ans.

# Install the argocd cli
~
❯ brew install argocd
~ 1h 11m 58s
❯ argocd version
argocd: v3.0.6+db93798
  BuildDate: 2025-06-09T22:57:47Z
  GitCommit: db93798d6643a565c056c6fda453e696719dbe12
  GitTreeState: clean
  GoVersion: go1.24.4
  Compiler: gc
  Platform: darwin/arm64
argocd-server: v2.14.11+8283115

~
❯

==> Two ways to login into the argocd server:
        1. Do a port forward (I am using this in my setup)
        ~/Desktop/Temporary
        ❯ kubectl --kubeconfig=k2 port-forward  svc/argocd-server -n argocd 8080:443
        Forwarding from 127.0.0.1:8080 -> 8080
        Forwarding from [::1]:8080 -> 8080


        ~/Desktop/Temporary
        ❯ argocd login 127.0.0.1:8080 --username admin --password Password1 --insecure

        'admin:login' logged in successfully
        Context '127.0.0.1:8080' updated

        ~/Desktop/Temporary
        ❯

        2. Change below to a NodePort and than use workerIP:externalPort to login
        kmaster2@kmaster2:~$ kubectl -n argocd get svc  | grep -i "argocd-server"
        argocd-server                      ClusterIP   10.110.139.175   <none>        80/TCP,443/TCP      52d
        kmaster2@kmaster2:~$


~/Desktop/Temporary 31s
❯ kubectl config --kubeconfig k1 get-contexts -o name
kubernetes-admin@kubernetes

~/Desktop/Temporary
❯

~/Desktop/Temporary
❯ argocd cluster add --kubeconfig k1 kubernetes-admin@kubernetes --name kmaster1

WARNING: This will create a service account `argocd-manager` on the cluster referenced by context `kubernetes-admin@kubernetes` with full cluster level privileges. Do you want to continue [y/N]? y
{"level":"info","msg":"ServiceAccount \"argocd-manager\" created in namespace \"kube-system\"","time":"2025-06-13T17:56:50-07:00"}
{"level":"info","msg":"ClusterRole \"argocd-manager-role\" created","time":"2025-06-13T17:56:50-07:00"}
{"level":"info","msg":"ClusterRoleBinding \"argocd-manager-role-binding\" created","time":"2025-06-13T17:56:50-07:00"}
{"level":"info","msg":"Created bearer token secret for ServiceAccount \"argocd-manager\"","time":"2025-06-13T17:56:50-07:00"}
Cluster 'https://10.235.174.70:6443' added

~/Desktop/Temporary 9s
❯

~/Desktop/Temporary
❯ argocd cluster list

SERVER                          NAME      VERSION  STATUS      MESSAGE                                                  PROJECT
https://kubernetes.default.svc  kmaster2  1.28     Successful
https://10.235.174.70:6443      kmaster1           Unknown     Cluster has no applications and is not being monitored.

~/Desktop/Temporary
❯

Add a app to the https://10.235.174.70:6443 & later on it changes to :

❯ argocd cluster list
SERVER                          NAME      VERSION  STATUS      MESSAGE  PROJECT
https://10.235.174.70:6443      kmaster1  1.28     Successful
https://kubernetes.default.svc  kmaster2  1.28     Successful

~
❯

❯ argocd cluster get kmaster1
config:
  tlsClientConfig:
    caData: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURCRENDQWV5Z0F3SUJBZ0lIVTZKYXFmS2hwakFOQmdrcWhraUc5dzBCQVFzRkFEQVZNUk13RVFZRFZRUUQKRXdwcmRXSmxjbTVsZEdWek1CNFhEVEkwTURreE1qSXhNVEl3TVZvWERUTTBNRGt4TURJeE1UY3dNVm93RlRFVApNQkVHQTFVRUF4TUthM1ZpWlhKdVpYUmxjekNDQVNJd0RRWUpLb1pJaHZjTkFRRUJCUUFEZ2dFUEFEQ0NBUW9DCmdnRUJBTG9WNVZCWFBGejBiNG9LNnhRN0szc3RpdzNYU2NLN3haelRoSjRWOVdnVUIvamxkWUl4dnF3aFdKRnYKRHlaOHc4T3d1RGFzRi95Wk5FSllKa2UydGRBcENXUEw4T0w2TmdYQitFS1lVTTUvME40K2M5MGV4b3hrU01UQgpsVzdTeldXalZ0OGZzSzBTL0VKaVN0Q24vczhBbXZSU3BDaXJsMnhDMzI1MkxhdUNKVUhXNEQ0SDNTS0tkemxrCjM5UDRRTWJsVXB4TmlzNFp6UjZBcVl3NHlycjZUU3NyYVhJak9PZHdFb1FaTlVXaEFRVUIwTzJPanN4REJKbEoKV3M1QVNHcURMbVZHUFByV01QWm5zS0VtMG15THlxNGtWcGhRYkM5M1JFb1ZLMUtiU3h1RytTM2pCaWxmWnhXZwp3MmVwZjYyOHgvem1YZHBWK0lKVHV0dkF5QjBDQXdFQUFhTlpNRmN3RGdZRFZSMFBBUUgvQkFRREFnS2tNQThHCkExVWRFd0VCL3dRRk1BTUJBZjh3SFFZRFZSME9CQllFRkdySi9iV1ZlcWZXbzBSRW4vTzBFMGZreUVOSU1CVUcKQTFVZEVRUU9NQXlDQ210MVltVnlibVYwWlhNd0RRWUpLb1pJaHZjTkFRRUxCUUFEZ2dFQkFLNTRxajFuVy9SYgpCb0cyTUNaN2h5ZmtjYTEzazNMdHQ3QkEwYU9lR3NhTjkydnlMNjF6RUg0SmxBcjdnQndjNEtWUEQwbnY2T2JmCkc1Z1N1ZVAwaThQOTYrRVlIK3pWZUJ5K0p1TVZWTlVBYzZseWZhK1JHNTZrWHBjWWRwSUZBSTVsbTQ3Q2RtcksKVkFlazkrRU9JdHRhcS91NjhleHdjWEFhUjNJNXNnNlFvSndkSFVTWlh5S1JycW1CTG50eVhQdTZpMGJVbHY5Uwo0cEEwVi9QbkpjZFF4UHhKZm9UV2NKTFhuU2RpVlJxR0tMRGFjWERjbHVmNVo5R3E0Q2w1eDFKdmhDbzFXWjNtCmJhb1NBRnNwekRwQ1JGYTB0cDQwVXNCSks0cHplVENPMXVMSHM3ZzhlRDhDVVpqOEwwVFFzc1hoUWpWelAwbk0KcTZRZG9OQ3ZrOWc9Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
    certData: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURJVENDQWdtZ0F3SUJBZ0lJWG1OUThwNmIyS2N3RFFZSktvWklodmNOQVFFTEJRQXdGVEVUTUJFR0ExVUUKQXhNS2EzVmlaWEp1WlhSbGN6QWVGdzB5TkRBNU1USXlNVEV5TURGYUZ3MHlOVEE1TVRJeU1URTNNRFJhTURReApGekFWQmdOVkJBb1REbk41YzNSbGJUcHRZWE4wWlhKek1Sa3dGd1lEVlFRREV4QnJkV0psY201bGRHVnpMV0ZrCmJXbHVNSUlCSWpBTkJna3Foa2lHOXcwQkFRRUZBQU9DQVE4QU1JSUJDZ0tDQVFFQXFJN2c0eVFEaUlqYUtERncKSXQwUVduYjg2a3NrZGthYjZtOENtNDBFZ3V1RGpucGJiM0hWMVM3M1hPQzRlOHl5VFQ0dXcxSlNVSWljcDFReQo3QkVoZ2pFNXNmNnVRYkNranZJQ1IrTTlqa2xrVGhqQkw3cUlONmtHSnFZVG83WlZMN3NXUWgrd0Y0TUg4azViCjB6U3J4cGdlb2FSTUxuNi9nNWJGOW95VkFRZWJPL3d4L0NLdUhhZW8vNHRpRTRsQjVCZTdvUEV1ZVdQTisxQzMKd0syUlZDMzFCeDhRVHRRNXFVK3FRaDFBc3p5eWJqYVMyWW03eDNIYW94YjUxZUV5allwYS9Uckp3S2prR0VxdQpLUEhvaHNCVlhtZnpiVUxHTGljdHFkVzdjQVZTZTNpaEoxMVllMitqc2pQQ211N3NNRHRETjllWWlxazlDak9xCk92UG5GUUlEQVFBQm8xWXdWREFPQmdOVkhROEJBZjhFQkFNQ0JhQXdFd1lEVlIwbEJBd3dDZ1lJS3dZQkJRVUgKQXdJd0RBWURWUjBUQVFIL0JBSXdBREFmQmdOVkhTTUVHREFXZ0JScXlmMjFsWHFuMXFORVJKL3p0Qk5INU1oRApTREFOQmdrcWhraUc5dzBCQVFzRkFBT0NBUUVBcWNKRHA0NVMwQWJSSHpnTjE0VHgwakk1MkozMnBFUEJXWm1JCkZIN0Z3N3VZRHlETStNTSsvTkFLUGtMTEtxaVducEtxRG5BaDRDcmV0ZWVYNjU4SEhZV3l5VXdCQVdkOVFFT0sKK1o5bnFCY0dFUU1IWXVrdnNNQndGUENaSkZqSGlLeEp1Q3ljSnhvSzJaNDJJQUFxSlpsSVp4OXRGYjI0RGpXNwpyQXFRYzZUWkFpbUdoUjYrTVdPQlFrN3FYdGVGZFFTWEZiSDRJUjdhZjFacUJlUEI0VDcxRTZ1UnRrQlNpSTJYCkgyR3ZoVjhmeEJidHBqV05LcHNpTlFhYUFUQkJOckphOHI5N1FiSjZ1cHQ2WVNlTWtKLzlTT0xkbjRRRm5Jb3gKb01UVjFETDUyWmJGUy9ZUFBicW9pUWw0dWZIZTJLWW5CTGhiZEFwZ29IeGdjTWFYMFE9PQotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg==
    insecure: false
connectionState:
  attemptedAt: "2025-06-16T21:40:40Z"
  message: ""
  status: Successful
info:
  apiVersions:
  - admissionregistration.k8s.io/v1
  - admissionregistration.k8s.io/v1/MutatingWebhookConfiguration
  - admissionregistration.k8s.io/v1/ValidatingWebhookConfiguration
  - apiextensions.k8s.io/v1
  - apiextensions.k8s.io/v1/CustomResourceDefinition
  - apiregistration.k8s.io/v1
  - apiregistration.k8s.io/v1/APIService
  - apps/v1
  - apps/v1/ControllerRevision
  - apps/v1/DaemonSet
  - apps/v1/Deployment
  - apps/v1/ReplicaSet
  - apps/v1/StatefulSet
  - autopilot.libopenstorage.org/v1alpha1
  - autopilot.libopenstorage.org/v1alpha1/ActionApproval
  - autopilot.libopenstorage.org/v1alpha1/AutopilotRule
  - autopilot.libopenstorage.org/v1alpha1/AutopilotRuleObject
  - autoscaling/v1
  - autoscaling/v1/HorizontalPodAutoscaler
  - autoscaling/v2
  - autoscaling/v2/HorizontalPodAutoscaler
  - batch/v1
  - batch/v1/CronJob
  - batch/v1/Job
  - certificates.k8s.io/v1
  - certificates.k8s.io/v1/CertificateSigningRequest
  - coordination.k8s.io/v1
  - coordination.k8s.io/v1/Lease
  - core.libopenstorage.org/v1
  - core.libopenstorage.org/v1/StorageCluster
  - core.libopenstorage.org/v1/StorageNode
  - crd.projectcalico.org/v1
  - crd.projectcalico.org/v1/BGPConfiguration
  - crd.projectcalico.org/v1/BGPFilter
  - crd.projectcalico.org/v1/BGPPeer
  - crd.projectcalico.org/v1/BlockAffinity
  - crd.projectcalico.org/v1/CalicoNodeStatus
  - crd.projectcalico.org/v1/ClusterInformation
  - crd.projectcalico.org/v1/FelixConfiguration
  - crd.projectcalico.org/v1/GlobalNetworkPolicy
  - crd.projectcalico.org/v1/GlobalNetworkSet
  - crd.projectcalico.org/v1/HostEndpoint
  - crd.projectcalico.org/v1/IPAMBlock
  - crd.projectcalico.org/v1/IPAMConfig
  - crd.projectcalico.org/v1/IPAMHandle
  - crd.projectcalico.org/v1/IPPool
  - crd.projectcalico.org/v1/IPReservation
  - crd.projectcalico.org/v1/KubeControllersConfiguration
  - crd.projectcalico.org/v1/NetworkPolicy
  - crd.projectcalico.org/v1/NetworkSet
  - discovery.k8s.io/v1
  - discovery.k8s.io/v1/EndpointSlice
  - events.k8s.io/v1
  - events.k8s.io/v1/Event
  - flowcontrol.apiserver.k8s.io/v1beta2
  - flowcontrol.apiserver.k8s.io/v1beta2/FlowSchema
  - flowcontrol.apiserver.k8s.io/v1beta2/PriorityLevelConfiguration
  - flowcontrol.apiserver.k8s.io/v1beta3
  - flowcontrol.apiserver.k8s.io/v1beta3/FlowSchema
  - flowcontrol.apiserver.k8s.io/v1beta3/PriorityLevelConfiguration
  - kdmp.portworx.com/v1alpha1
  - kdmp.portworx.com/v1alpha1/DataExport
  - kdmp.portworx.com/v1alpha1/ResourceBackup
  - kdmp.portworx.com/v1alpha1/ResourceExport
  - kdmp.portworx.com/v1alpha1/VolumeBackup
  - monitoring.coreos.com/v1
  - monitoring.coreos.com/v1/Alertmanager
  - monitoring.coreos.com/v1/PodMonitor
  - monitoring.coreos.com/v1/Probe
  - monitoring.coreos.com/v1/Prometheus
  - monitoring.coreos.com/v1/PrometheusRule
  - monitoring.coreos.com/v1/ServiceMonitor
  - monitoring.coreos.com/v1/ThanosRuler
  - monitoring.coreos.com/v1alpha1
  - monitoring.coreos.com/v1alpha1/AlertmanagerConfig
  - networking.k8s.io/v1
  - networking.k8s.io/v1/Ingress
  - networking.k8s.io/v1/IngressClass
  - networking.k8s.io/v1/NetworkPolicy
  - node.k8s.io/v1
  - node.k8s.io/v1/RuntimeClass
  - operator.tigera.io/v1
  - operator.tigera.io/v1/APIServer
  - operator.tigera.io/v1/ImageSet
  - operator.tigera.io/v1/Installation
  - operator.tigera.io/v1/TigeraStatus
  - policy/v1
  - policy/v1/PodDisruptionBudget
  - portworx.io/v1beta2
  - portworx.io/v1beta2/VolumePlacementStrategy
  - projectcalico.org/v3
  - projectcalico.org/v3/BGPConfiguration
  - projectcalico.org/v3/BGPFilter
  - projectcalico.org/v3/BGPPeer
  - projectcalico.org/v3/BlockAffinity
  - projectcalico.org/v3/CalicoNodeStatus
  - projectcalico.org/v3/ClusterInformation
  - projectcalico.org/v3/FelixConfiguration
  - projectcalico.org/v3/GlobalNetworkPolicy
  - projectcalico.org/v3/GlobalNetworkSet
  - projectcalico.org/v3/HostEndpoint
  - projectcalico.org/v3/IPAMConfiguration
  - projectcalico.org/v3/IPPool
  - projectcalico.org/v3/IPReservation
  - projectcalico.org/v3/KubeControllersConfiguration
  - projectcalico.org/v3/NetworkPolicy
  - projectcalico.org/v3/NetworkSet
  - projectcalico.org/v3/Profile
  - rbac.authorization.k8s.io/v1
  - rbac.authorization.k8s.io/v1/ClusterRole
  - rbac.authorization.k8s.io/v1/ClusterRoleBinding
  - rbac.authorization.k8s.io/v1/Role
  - rbac.authorization.k8s.io/v1/RoleBinding
  - scheduling.k8s.io/v1
  - scheduling.k8s.io/v1/PriorityClass
  - snapshot.storage.k8s.io/v1
  - snapshot.storage.k8s.io/v1/VolumeSnapshot
  - snapshot.storage.k8s.io/v1/VolumeSnapshotClass
  - snapshot.storage.k8s.io/v1/VolumeSnapshotContent
  - snapshot.storage.k8s.io/v1beta1
  - snapshot.storage.k8s.io/v1beta1/VolumeSnapshot
  - snapshot.storage.k8s.io/v1beta1/VolumeSnapshotClass
  - snapshot.storage.k8s.io/v1beta1/VolumeSnapshotContent
  - storage.k8s.io/v1
  - storage.k8s.io/v1/CSIDriver
  - storage.k8s.io/v1/CSINode
  - storage.k8s.io/v1/CSIStorageCapacity
  - storage.k8s.io/v1/StorageClass
  - storage.k8s.io/v1/VolumeAttachment
  - stork.libopenstorage.org/v1alpha1
  - stork.libopenstorage.org/v1alpha1/Action
  - stork.libopenstorage.org/v1alpha1/ApplicationBackup
  - stork.libopenstorage.org/v1alpha1/ApplicationBackupSchedule
  - stork.libopenstorage.org/v1alpha1/ApplicationClone
  - stork.libopenstorage.org/v1alpha1/ApplicationRegistration
  - stork.libopenstorage.org/v1alpha1/ApplicationRestore
  - stork.libopenstorage.org/v1alpha1/BackupLocation
  - stork.libopenstorage.org/v1alpha1/ClusterDomainUpdate
  - stork.libopenstorage.org/v1alpha1/ClusterDomainsStatus
  - stork.libopenstorage.org/v1alpha1/ClusterPair
  - stork.libopenstorage.org/v1alpha1/GroupVolumeSnapshot
  - stork.libopenstorage.org/v1alpha1/Migration
  - stork.libopenstorage.org/v1alpha1/MigrationSchedule
  - stork.libopenstorage.org/v1alpha1/NamespacedSchedulePolicy
  - stork.libopenstorage.org/v1alpha1/PlatformCredential
  - stork.libopenstorage.org/v1alpha1/ResourceTransformation
  - stork.libopenstorage.org/v1alpha1/Rule
  - stork.libopenstorage.org/v1alpha1/SchedulePolicy
  - stork.libopenstorage.org/v1alpha1/VolumeSnapshotRestore
  - stork.libopenstorage.org/v1alpha1/VolumeSnapshotSchedule
  - v1
  - v1/ConfigMap
  - v1/Endpoints
  - v1/Event
  - v1/LimitRange
  - v1/Namespace
  - v1/Node
  - v1/PersistentVolume
  - v1/PersistentVolumeClaim
  - v1/Pod
  - v1/PodTemplate
  - v1/ReplicationController
  - v1/ResourceQuota
  - v1/Secret
  - v1/Service
  - v1/ServiceAccount
  - volumesnapshot.external-storage.k8s.io/v1
  - volumesnapshot.external-storage.k8s.io/v1/VolumeSnapshot
  - volumesnapshot.external-storage.k8s.io/v1/VolumeSnapshotData
  applicationsCount: 0
  cacheInfo:
    apisCount: 127
    lastCacheSyncTime: "2025-06-14T21:11:05Z"
    resourcesCount: 740
  connectionState:
    attemptedAt: "2025-06-16T21:40:40Z"
    message: ""
    status: Successful
  serverVersion: "1.28"
name: kmaster1
server: https://10.235.174.70:6443
serverVersion: "1.28"

~
❯
//--------------------------------------------------------------------------------------------------------------
Ques. Get a list of apps installed ?
Ans.
❯ argocd app list
NAME                     CLUSTER                         NAMESPACE   PROJECT  STATUS  HEALTH   SYNCPOLICY  CONDITIONS  REPO                                                                      PATH          TARGET
argocd/grade-submission  https://kubernetes.default.svc  grade-demo  default  Synced  Healthy  Auto-Prune  <none>      https://github.com/upinder-sujlana/argocd-kubernetes-gitops-tutorial.git  gitops/basic  HEAD

~
❯
~
❯ argocd app get argocd/grade-submission -o wide
Name:               argocd/grade-submission
Project:            default
Server:             https://kubernetes.default.svc
Namespace:          grade-demo
URL:                https://argocd.example.com/applications/grade-submission
Source:
- Repo:             https://github.com/upinder-sujlana/argocd-kubernetes-gitops-tutorial.git
  Target:           HEAD
  Path:             gitops/basic
SyncWindow:         Sync Allowed
Sync Policy:        Automated (Prune)
Sync Status:        Synced to HEAD (1a549a1)
Health Status:      Healthy

GROUP  KIND        NAMESPACE   NAME                  STATUS  HEALTH   HOOK  MESSAGE
       Service     grade-demo  grade-submission-api  Synced  Healthy        service/grade-submission-api unchanged
apps   Deployment  grade-demo  grade-submission-api  Synced  Healthy        deployment.apps/grade-submission-api configured

~
❯
//--------------------------------------------------------------------------------------------------------------
Ques. get the logs of a installed app ?
Ans.
❯ argocd app logs argocd/grade-submission
{"level":"info","message":"Grade service is running on port 3000","service":"grade-service"}
{"level":"info","message":"Grade service is running on port 3000","service":"grade-service"}
{"level":"info","message":"Application is ready to serve requests","service":"grade-service"}
{"level":"info","message":"Application is ready to serve requests","service":"grade-service"}
{"level":"info","message":"Grade service is running on port 3000","service":"grade-service"}
{"level":"info","message":"Application is ready to serve requests","service":"grade-service"}
{"level":"info","message":"Grade service is running on port 3000","service":"grade-service"}
{"level":"info","message":"Grade service is running on port 3000","service":"grade-service"}
{"level":"info","message":"Application is ready to serve requests","service":"grade-service"}
{"level":"info","message":"Application is ready to serve requests","service":"grade-service"}

~
❯
//--------------------------------------------------------------------------------------------------------------
Ques. Sync app from cli ?
Ans.
Careful below will change sync to manually~
❯ argocd app sync argocd/grade-submission
TIMESTAMP                  GROUP        KIND   NAMESPACE                  NAME    STATUS   HEALTH        HOOK  MESSAGE
2025-06-16T16:58:46-07:00   apps  Deployment  grade-demo  grade-submission-api    Synced  Healthy              deployment.apps/grade-submission-api unchanged
2025-06-16T16:58:46-07:00            Service  grade-demo  grade-submission-api    Synced  Healthy              service/grade-submission-api unchanged

Name:               argocd/grade-submission
Project:            default
Server:             https://kubernetes.default.svc
Namespace:          grade-demo
URL:                https://argocd.example.com/applications/argocd/grade-submission
Source:
- Repo:             https://github.com/upinder-sujlana/argocd-kubernetes-gitops-tutorial.git
  Target:           HEAD
  Path:             gitops/basic
SyncWindow:         Sync Allowed
Sync Policy:        Automated (Prune)
Sync Status:        Synced to HEAD (1a549a1)
Health Status:      Healthy

Operation:          Sync
Sync Revision:      1a549a1a19edddadfbf510730241eac77b1159aa
Phase:              Succeeded
Start:              2025-06-16 16:58:45 -0700 PDT
Finished:           2025-06-16 16:58:46 -0700 PDT
Duration:           1s
Message:            successfully synced (all tasks run)

GROUP  KIND        NAMESPACE   NAME                  STATUS  HEALTH   HOOK  MESSAGE
       Service     grade-demo  grade-submission-api  Synced  Healthy        service/grade-submission-api unchanged
apps   Deployment  grade-demo  grade-submission-api  Synced  Healthy        deployment.apps/grade-submission-api unchanged

~
❯

//--------------------------------------------------------------------------------------------------------------
Ques. Check the projects in argocd ?
Ans.
~
❯ argocd proj list
NAME     DESCRIPTION  DESTINATIONS  SOURCES  CLUSTER-RESOURCE-WHITELIST  NAMESPACE-RESOURCE-BLACKLIST  SIGNATURE-KEYS  ORPHANED-RESOURCES  DESTINATION-SERVICE-ACCOUNTS
default               *,*           *        */*                         <none>                        <none>          disabled            <none>

~
❯
//--------------------------------------------------------------------------------------------------------------
Ques. Helm - Create a app from argocd cli ?
Ans.
❯ argocd cluster list
SERVER                          NAME      VERSION  STATUS      MESSAGE                                                  PROJECT
https://10.235.174.70:6443      kmaster1           Unknown     Cluster has no applications and is not being monitored.
https://kubernetes.default.svc  kmaster2  1.28     Successful

~
❯

❯  argocd app create helmdemo --repo https://github.com/yogeshraheja/Argo-CD-for-the-Absolute-Beginners.git --path Section10_Helm_Charts/demotest --dest-server https://kubernetes.default.svc
application 'helmdemo' created

~
❯
Above will create a Manual sync app. Now we sync it:-

❯ argocd app sync argocd/helmdemo

~
❯ argocd app list
NAME                     CLUSTER                         NAMESPACE   PROJECT  STATUS  HEALTH   SYNCPOLICY  CONDITIONS  REPO                                                                      PATH                            TARGET
argocd/grade-submission  https://kubernetes.default.svc  grade-demo  default  Synced  Healthy  Auto-Prune  <none>      https://github.com/upinder-sujlana/argocd-kubernetes-gitops-tutorial.git  gitops/basic                    HEAD
argocd/helmdemo          https://kubernetes.default.svc              default  Synced  Healthy  Manual      <none>      https://github.com/yogeshraheja/Argo-CD-for-the-Absolute-Beginners.git    Section10_Helm_Charts/demotest

~
❯
//--------------------------------------------------------------------------------------------------------------
Ques. Delete the app with a confirmation flag ?
Ans.
❯ argocd app list
NAME                     CLUSTER                         NAMESPACE   PROJECT  STATUS  HEALTH   SYNCPOLICY  CONDITIONS  REPO                                                                      PATH                            TARGET
argocd/grade-submission  https://kubernetes.default.svc  grade-demo  default  Synced  Healthy  Auto-Prune  <none>      https://github.com/upinder-sujlana/argocd-kubernetes-gitops-tutorial.git  gitops/basic                    HEAD
argocd/helmdemo          https://kubernetes.default.svc              default  Synced  Healthy  Manual      <none>      https://github.com/yogeshraheja/Argo-CD-for-the-Absolute-Beginners.git    Section10_Helm_Charts/demotest

~
❯
❯ argocd app delete argocd/helmdemo --yes

application 'argocd/helmdemo' deleted

~
❯
//--------------------------------------------------------------------------------------------------------------
helm repo add portworx http://charts.portworx.io/ && helm repo update

helm install px-central portworx/px-central --namespace central --create-namespace --version 2.8.4 --set persistentStorage.enabled=true,persistentStorage.storageClassName="px-csi-db",pxbackup.enabled=true
//--------------------------------------------------------------------------------------------------------------
